{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 121411])\n",
      "torch.Size([80, 475])\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import HIFIGAN\n",
    "from speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n",
    "\n",
    "# Load a pretrained HIFIGAN Vocoder\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-libritts-16kHz\", savedir=\"vocoder_16khz\", run_opts={\"device\":\"cuda\"})\n",
    "\n",
    "# Load an audio file (an example file can be found in this repository)\n",
    "# Ensure that the audio signal is sampled at 16000 Hz\n",
    "signal, rate = torchaudio.load(r'C:\\Users\\JadHa\\Desktop\\Uni\\Audio SP\\VoiceConversion\\VCTK-Corpus-0.92\\wav48_silence_trimmed\\p225\\p225_003_mic1.flac')\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)\n",
    "signal = resampler(signal)\n",
    "print(signal.shape)\n",
    "\n",
    "# Ensure the audio is single channel\n",
    "signal = signal[0].squeeze()\n",
    "\n",
    "torchaudio.save('waveform.wav', signal.unsqueeze(0).cpu(), 16000)\n",
    "\n",
    "# Compute the mel spectrogram.\n",
    "# IMPORTANT: Use these specific parameters to match the Vocoder's training settings for optimal results.\n",
    "spectrogram, _ = mel_spectogram(\n",
    "    audio=signal.squeeze(),\n",
    "    sample_rate=16000,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    n_mels=80,\n",
    "    n_fft=1024,\n",
    "    f_min=0.0,\n",
    "    f_max=8000.0,\n",
    "    power=1,\n",
    "    normalized=False,\n",
    "    min_max_energy_norm=True,\n",
    "    norm=\"slaney\",\n",
    "    mel_scale=\"slaney\",\n",
    "    compression=True\n",
    ")\n",
    "\n",
    "print(spectrogram.shape)\n",
    "\n",
    "# Convert the spectrogram to waveform\n",
    "waveforms = hifi_gan.decode_batch(spectrogram)\n",
    "\n",
    "# Save the reconstructed audio as a waveform\n",
    "torchaudio.save('waveform_reconstructed.wav', waveforms.squeeze(1).cpu(), 16000)\n",
    "\n",
    "# If everything is set up correctly, the original and reconstructed audio should be nearly indistinguishable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
